{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb78d9cc-4b13-4bb5-9963-f2e2f81f820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b27639e-2a35-4d83-9f66-c9f22c7b4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7feae1-b8a8-43a2-8a79-5f121b4ee485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6455eb2-5305-469b-be0a-14b0a40aef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "15782236-f7fe-44b4-b6ce-b199c926ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdea49b9-a133-441f-b955-934aa75873f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73357ba4-e9fa-44d8-876f-10fbe4333e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04cc7d-ed51-4c69-b46d-65474f9b5418",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0dad4fde-3c39-483d-9af9-6336882e6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f56bc5d4-e555-4436-ae25-33b765261466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c946cca3-005c-4b69-af7b-2348ba2386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774109f-c1cc-44bb-b374-2f646925e4f9",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7889fc0-3058-442f-b449-bdd3b81148eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be used by default. Shows best results on intrinsic evaluations.\n",
    "# Model was trained on large corpus of an literature (~150GB).\n",
    "\n",
    "# !wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9724fa51-d904-43ea-a293-4bf72d1dcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dce022-5e2a-4587-90cd-ad959a159340",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b60ca58-b91d-4da6-af70-340573dc2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ceebadd-c435-4d31-8882-b0e2ab4e456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243e287-01bc-4ab7-b0c8-ca967519d21c",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea33e80d-d55f-48c2-a283-f1590f451eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45f5bf1-2006-4efe-8e46-64781b31bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "\n",
    "plt.style.use('science')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "lables_fs = 16\n",
    "ticks_fs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d20c59-3418-4546-9d3c-190d19d038f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810418a-5395-4841-a942-8a3f6723ed86",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5a7bce-8d67-4c98-8a84-8c1e91dc0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dir = '../data/prepared'\n",
    "filename_csv = '02_punct_pushkin.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d63ad3-3b17-4217-aefb-c25a5737672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4456, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved dataset\n",
    "data_df = pd.read_csv(os.path.join(prepared_dir, filename_csv), index_col=0)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d182437e-874a-4068-9ebd-d63755fbd039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>input_lemma</th>\n",
       "      <th>new_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>там они были схвачены 16 казаками и выданы победителю который отослал их скованных в уфу</td>\n",
       "      <td>там они быть схватить 16 казак и выдать победитель который отослать они сковать в уфа</td>\n",
       "      <td>S S S S S S S S C S S S S S F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>как досадно подумал алексей</td>\n",
       "      <td>как досадно подумать алексей</td>\n",
       "      <td>S C S F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>я сам отвечал граф с видом чрезвычайно расстроенным а простреленная картина есть памятник последней нашей встречи</td>\n",
       "      <td>я сам отвечать граф с вид чрезвычайно расстроить а прострелить картина быть памятник последний наш встреча</td>\n",
       "      <td>S C S S S S S C S S S S S S S F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>кто в минуту гнева не требовал от них роковой книги дабы вписать в оную свою бесполезную жалобу на притеснение грубость и неисправность</td>\n",
       "      <td>кто в минута гнев не требовать от они роковой книга дабы вписать в оную свой бесполезный жалоба на притеснение грубость и неисправность</td>\n",
       "      <td>C S S C S S S S S C S S S S S S S S C S S F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>в берде найдено осьмнадцать пушек семнадцать бочек медных денег 13 и множество хлеба</td>\n",
       "      <td>в берда найти осьмнадцать пушка семнадцать бочка медный деньга 13 и множество хлеб</td>\n",
       "      <td>S S S S C S S S S S S S F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        input  \\\n",
       "2373                                                 там они были схвачены 16 казаками и выданы победителю который отослал их скованных в уфу   \n",
       "4447                                                                                                              как досадно подумал алексей   \n",
       "3798                        я сам отвечал граф с видом чрезвычайно расстроенным а простреленная картина есть памятник последней нашей встречи   \n",
       "4067  кто в минуту гнева не требовал от них роковой книги дабы вписать в оную свою бесполезную жалобу на притеснение грубость и неисправность   \n",
       "2350                                                     в берде найдено осьмнадцать пушек семнадцать бочек медных денег 13 и множество хлеба   \n",
       "\n",
       "                                                                                                                                  input_lemma  \\\n",
       "2373                                                    там они быть схватить 16 казак и выдать победитель который отослать они сковать в уфа   \n",
       "4447                                                                                                             как досадно подумать алексей   \n",
       "3798                               я сам отвечать граф с вид чрезвычайно расстроить а прострелить картина быть памятник последний наш встреча   \n",
       "4067  кто в минута гнев не требовать от они роковой книга дабы вписать в оную свой бесполезный жалоба на притеснение грубость и неисправность   \n",
       "2350                                                       в берда найти осьмнадцать пушка семнадцать бочка медный деньга 13 и множество хлеб   \n",
       "\n",
       "                                       new_target  \n",
       "2373                S S S S S S S S C S S S S S F  \n",
       "4447                                      S C S F  \n",
       "3798              S C S S S S S C S S S S S S S F  \n",
       "4067  C S S C S S S S S C S S S S S S S S C S S F  \n",
       "2350                    S S S S C S S S S S S S F  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 150\n",
    "data_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3457b-4f54-4faf-a500-99beb91b7a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6d2121-398d-44ea-a4c9-45c510c2b65d",
   "metadata": {},
   "source": [
    "## Pretrained Embeddings\n",
    "\n",
    "In that implementation we will use [`navec`](https://github.com/natasha/navec#evaluation) library of pretrained word embeddings for Russian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04b578d7-aa87-4fad-b19d-e0fbfe000bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec_embed = Navec.load(navec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6ba7582-d88b-4bfe-833f-15f38e908a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39912c-0a1c-4b74-914a-f703b943b368",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a49e092e-ac5e-416f-b8cf-f46a61011de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мы поцеловались горячо искренно и таким образом все было между нами решено'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_sent = data_df.loc[1321]['input'] # data_df.sample(1)['input'].item()\n",
    "ex_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49c94cdc-61b6-4ed7-951f-3290ce79638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_embed_tensor = None\n",
    "\n",
    "for word in ex_sent.split():\n",
    "    word_embed = navec_embed[word]\n",
    "    \n",
    "    assert len(word_embed) == EMBED_SIZE\n",
    "    assert isinstance(word_embed, np.ndarray)\n",
    "\n",
    "    word_embed_tensor = torch.tensor(word_embed)\n",
    "    word_embed_tensor = word_embed_tensor.unsqueeze(dim=0)\n",
    "\n",
    "    # size of word embedding: 1 * embed_size\n",
    "    assert word_embed_tensor.size() == (1, EMBED_SIZE)\n",
    "\n",
    "    if sent_embed_tensor is None:\n",
    "        sent_embed_tensor = word_embed_tensor\n",
    "    else:\n",
    "        sent_embed_tensor = torch.cat(\n",
    "            (sent_embed_tensor, word_embed_tensor), \n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "# size of sentence tensor: n_words * embed_size\n",
    "assert sent_embed_tensor.size() == (len(ex_sent.split()), EMBED_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fd4a8db-5bb7-4421-b29a-89021d59b7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed_tensor.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe190c53-907b-4416-bb19-2ac9617ab3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navec_embed['<pad>'][:10]  # padding: all zeros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9fb1c234-9060-43e5-b071-98a252a8a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'чушь-чепуха' in navec_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a64abb-cdcf-4e80-aae6-2d5fc2cd3a1c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**In that approach** we will use _original_ (not lemmatized) sentences as input (`input` column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6840e3d-77ec-4023-aec6-9115a2ae506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_ID = -1  # token id to ignore\n",
    "\n",
    "# punctuation vocab\n",
    "PUNC_2_ID = {'S': 0, 'C': 1, 'F':2}\n",
    "ID_2_PUNC = {v: k for k, v in PUNC_2_ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6d91db7-10b0-46b2-b788-d507743900b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = '<pad>'\n",
    "UNK = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7540fb6-a26f-4e09-b9ba-eb9b2ef9ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuncDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for punctuation prediction\"\"\"\n",
    "\n",
    "    def __init__(self, df, sent_col, target_col, embed):\n",
    "        self.sentences = df[sent_col]  # all sentences\n",
    "        self.targets = df[target_col]  # all targets\n",
    "\n",
    "        self.embed = embed  # navec embedding\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of sentences\"\"\"\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return one Tensor pair of (input id sequence, punc id sequence)\"\"\"\n",
    "        sentence = self.sentences[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        word_id_seq, punc_id_seq = self._preprocess(sentence, target)\n",
    "        return word_id_seq, punc_id_seq\n",
    "\n",
    "    def _preprocess(self, sentence, target):\n",
    "        \"\"\"Convert txt sequence to word-id-seq and punc-id-seq\"\"\"\n",
    "        # INPUT\n",
    "        input_tensor = None\n",
    "        \n",
    "        for word in sentence.split():\n",
    "            if word in self.embed:  # if word in vocab\n",
    "                word_embed = navec_embed[word]\n",
    "            else:\n",
    "                word_embed = navec_embed[UNK]\n",
    "    \n",
    "            assert len(word_embed) == EMBED_SIZE\n",
    "            assert isinstance(word_embed, np.ndarray)\n",
    "        \n",
    "            word_embed_tensor = torch.tensor(word_embed)  # size: [embed_size]\n",
    "            word_embed_tensor = word_embed_tensor.unsqueeze(dim=0)  # size: [1, embed_size]\n",
    "        \n",
    "            assert word_embed_tensor.size() == (1, EMBED_SIZE)\n",
    "        \n",
    "            if input_tensor is None:\n",
    "                input_tensor = word_embed_tensor\n",
    "            else:\n",
    "                input_tensor = torch.cat(\n",
    "                    (input_tensor, word_embed_tensor), \n",
    "                    dim=0\n",
    "                )\n",
    "        # size: [len_sent, embed_size]\n",
    "        assert input_tensor.size() == (len(sentence.split()), EMBED_SIZE)\n",
    "        \n",
    "        # OUTPUT\n",
    "        output_seq = []\n",
    "        for punc in target.split():\n",
    "            output_seq.append(PUNC_2_ID.get(punc))\n",
    "\n",
    "        assert input_tensor.size()[0] == len(output_seq)\n",
    "\n",
    "        return input_tensor, torch.LongTensor(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb84abd4-5c18-4d11-970a-872ff1a111e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4456\n"
     ]
    }
   ],
   "source": [
    "data_ds = PuncDataset(\n",
    "    df=data_df, \n",
    "    sent_col='input', \n",
    "    target_col='new_target',\n",
    "    embed=navec_embed\n",
    ")\n",
    "\n",
    "print(len(data_ds))  # dataset length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5700fa9-ba8e-453b-89cc-83719b14aa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0693, -0.7137,  0.1012,  ..., -0.5967, -0.1622,  0.1446],\n",
       "         [-0.5378, -0.6289, -0.3964,  ..., -0.4420, -0.1768,  0.5108],\n",
       "         [-0.5378, -0.6289, -0.3964,  ..., -0.2754,  0.0252,  0.3528],\n",
       "         ...,\n",
       "         [-0.0273, -0.1946, -0.1695,  ..., -0.0571,  0.1050,  0.3030],\n",
       "         [-0.2140,  0.2572, -0.2415,  ...,  0.4958,  0.5133,  0.0219],\n",
       "         [-0.0460,  0.0078,  0.3391,  ...,  0.0026, -0.0379, -0.0747]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ds[1111]  # example of dataset element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b6d0a-03e7-4555-aa79-950a16e2ebbc",
   "metadata": {},
   "source": [
    "### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9b8f693-3640-448d-a166-bdaaa8affee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "   Process one mini-batch samples, such as sorting and padding.\n",
    "    Args:\n",
    "        batch: a list of (sentence tensor, targets tensor)\n",
    "    Returns:\n",
    "        input_padded_tensor\n",
    "        output_padded_tensor\n",
    "        lengths\n",
    "    \"\"\"\n",
    "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "    # seperate inputs and labels\n",
    "    input_tensors, label_seqs = zip(*batch)\n",
    "    # padding\n",
    "    lengths = [len(seq) for seq in label_seqs]\n",
    "    bs = len(label_seqs)\n",
    "    max_sent_len = max(lengths)\n",
    "    \n",
    "        # shape: [batch_size, max_sent_len, embed_size]\n",
    "    input_padded_tensor = torch.zeros(bs, max_sent_len, EMBED_SIZE)  # zeros are the padding for navec!\n",
    "        # shape: [batch_size, max_sent_len]\n",
    "    output_padded_tensor = torch.zeros(bs, max_sent_len).fill_(IGNORE_ID).long()\n",
    "    \n",
    "    for i, (input_tensor, output_seq) in enumerate(zip(input_tensors, label_seqs)):\n",
    "        end = lengths[i]\n",
    "        input_padded_tensor[i, :end, :] = input_tensor[:end, :]\n",
    "        output_padded_tensor[i, :end] = output_seq[:end]\n",
    "        \n",
    "    return input_padded_tensor, output_padded_tensor, torch.IntTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2b496b7c-40b1-4b1f-9af3-b8ee53e96851",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    data_ds,\n",
    "    batch_size=10, \n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,  # custom collate function6 defined above!\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2c9c17a9-69ef-459c-934d-28bd6b93dbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 24, 300])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3f596-efa3-4037-8c8d-58d8fe0524e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0463282f-5cd6-4632-9793-cde69f674fee",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "971f53cb-f007-4a32-8c7e-b453afcde54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmPunctuator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size, num_layers, bidirectional,\n",
    "        num_class, dropout=0.0\n",
    "    ):\n",
    "        super(LstmPunctuator, self).__init__()\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_class = num_class\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Components\n",
    "        self.lstm = nn.LSTM(\n",
    "            EMBED_SIZE, hidden_size, num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bool(bidirectional),\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "        fc_in_dim = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc = nn.Linear(fc_in_dim, num_class)\n",
    "\n",
    "    def forward(self, padded_input, input_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            padded_input: [bs, max_sent_len, EMBED_SIZE]\n",
    "            input_lengths: [bs]\n",
    "        Returns:\n",
    "            score: [bs, max_sent_len, num_classes]\n",
    "        \"\"\"\n",
    "        # LSTM Layers\n",
    "        total_length = padded_input.size(1)  # get the max sequence length\n",
    "        packed_input = pack_padded_sequence(\n",
    "            padded_input, input_lengths,\n",
    "            batch_first=True\n",
    "        )\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(\n",
    "            packed_output,\n",
    "            batch_first=True,\n",
    "            total_length=total_length\n",
    "        )\n",
    "        # Output Layer\n",
    "        score = self.fc(output)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "287941dc-598f-46ee-b523-4521e450fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GruPunctuator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size, num_layers, bidirectional,\n",
    "        num_class, dropout=0.0\n",
    "    ):\n",
    "        super(GruPunctuator, self).__init__()\n",
    "        \n",
    "        # Hyper-parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_class = num_class\n",
    "        self.dropout = dropout\n",
    "        self.gru_h = None\n",
    "        \n",
    "        # Components\n",
    "        self.gru = nn.GRU(\n",
    "            EMBED_SIZE, hidden_size, num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bool(bidirectional),\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "        fc_in_dim = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.fc = nn.Linear(fc_in_dim, num_class)\n",
    "\n",
    "    def forward(self, padded_input, input_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            padded_input: [bs, max_sent_len, EMBED_SIZE]\n",
    "            input_lengths: [bs]\n",
    "        Returns:\n",
    "            score: [bs, max_sent_len, num_classes]\n",
    "        \"\"\"\n",
    "        # LSTM Layers\n",
    "        total_length = padded_input.size(1)  # get the max sequence length\n",
    "        packed_input = pack_padded_sequence(\n",
    "            padded_input, input_lengths,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.reset_hidden(padded_input.size(0))\n",
    "        packed_output, gru_h = self.gru(packed_input, self.gru_h)\n",
    "        # self.gru_h = gru_h.detach()\n",
    "        \n",
    "        output, _ = pad_packed_sequence(\n",
    "            packed_output,\n",
    "            batch_first=True,\n",
    "            total_length=total_length\n",
    "        )\n",
    "        # Output Layer\n",
    "        score = self.fc(output)\n",
    "        return score\n",
    "\n",
    "    def reset_hidden(self, batch_size):\n",
    "        size_0 = self.num_layers * 2 if self.bidirectional else self.num_layers\n",
    "        self.gru_h = torch.zeros(size_0 , batch_size, self.hidden_size)  # .to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7124ef-fa84-4e4f-acff-7c25e2292966",
   "metadata": {},
   "source": [
    "## Training and Evaluationg loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5f657e36-5cc4-4150-b702-365e88de5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, loss_func, optimizer,\n",
    "             device='cpu', show_process=False):\n",
    "    '''\n",
    "    Function to train `model`\n",
    "    Args:\n",
    "        model: torch.nn.Module - Neural Network\n",
    "        data_loader: torch.utils.data.DataLoader - loader (by batches) for the train dataset\n",
    "        loss_func - loss function\n",
    "        optimizer: torch.optim\n",
    "        device: str - device to computate on\n",
    "        show_process: bool - flag to show (or not) a progress bar\n",
    "    Returns:\n",
    "        mean loss by batches\n",
    "    '''\n",
    "    model.train()  # activate 'train' mode of a model\n",
    "    train_loss = []  # to store loss for each batch\n",
    "\n",
    "    for X, y, y_lengths in tqdm(data_loader, total=len(data_loader),\n",
    "                                desc='train', position=0,\n",
    "                                leave=True, disable=not show_process):  # [X, y] - batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_lengths = y_lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(X, y_lengths)  # size: [bs, max_sent_length, num_classes]\n",
    "\n",
    "        y_hat = y_hat.view(-1, y_hat.size(-1))\n",
    "        loss = loss_func(y_hat, y.view(-1))  # loss calculation for the batch\n",
    "        \n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())  # accumulate losses for batches\n",
    "\n",
    "    return np.mean(train_loss)  # return mean loss of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c41a1eee-7086-44d4-84c6-5b5eb6a8efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_fn(model, data_loader, loss_func,\n",
    "                device='cpu', show_process=False):\n",
    "    '''\n",
    "    Function to train `model`\n",
    "    Args:\n",
    "        model: torch.nn.Module - Neural Network\n",
    "        data_loader: torch.utils.data.DataLoader - loader (by batches) for the validation dataset\n",
    "        loss_func - loss function\n",
    "        device: str - device to computate on\n",
    "        show_process: bool - flag to show (or not) a progress bar\n",
    "    Returns:\n",
    "          mean loss by batches\n",
    "    '''\n",
    "    model.eval()  # activate 'eval' mode of a model\n",
    "    val_loss = []  # to store loss for each batch\n",
    "\n",
    "    for X, y, y_lengths in tqdm(data_loader, total=len(data_loader),\n",
    "                                desc='validation', position=0,\n",
    "                                leave=True, disable=not show_process):  # [X, y] - batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_lengths = y_lengths.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(X, y_lengths)  # size: [bs, max_sent_length, num_classes]\n",
    "\n",
    "            y_hat = y_hat.view(-1, y_hat.size(-1))\n",
    "            loss = loss_func(y_hat, y.view(-1))  # loss calculation for the batch\n",
    "\n",
    "        val_loss.append(loss.item())  # accumulate losses for batches\n",
    "\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c444626-8de5-40e5-8670-947272b3a430",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9df44b-8667-4a29-bfbc-ae92117aa2c6",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6a8332de-a8ce-482c-829a-b80d5f5ae01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_random_state = 78\n",
    "test_ratio = 0.25\n",
    "\n",
    "train_bs = 15\n",
    "val_bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d2f8fcb9-96e0-4e9c-95c3-da9f42c314e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "train_df, test_df = train_test_split(\n",
    "    data_df, \n",
    "    test_size=test_ratio, \n",
    "    random_state=splitting_random_state\n",
    ")\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2e219916-0a05-4bbd-be2a-0cdbe9c55756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_ds = PuncDataset(\n",
    "    df=train_df, \n",
    "    sent_col='input', \n",
    "    target_col='new_target',\n",
    "    embed=navec_embed\n",
    ")\n",
    "\n",
    "test_ds = PuncDataset(\n",
    "    df=test_df, \n",
    "    sent_col='input', \n",
    "    target_col='new_target',\n",
    "    embed=navec_embed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "35ee8dce-f213-4e36-952f-a1e25f159eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_bs, \n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=val_bs, \n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec685a78-230a-415a-9b93-c5662a53e1b3",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "3d09e458-d97a-4df5-a8b8-8d3dabcb3e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "287764f3-a6ef-4841-9452-aca76a580a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "hidden_sz = 32\n",
    "num_layers = 2\n",
    "bidir = 1\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ec3afd75-b2fc-4e92-ab38-d85e8c359752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = LstmPunctuator(\n",
    "    hidden_size=hidden_sz, num_layers=num_layers, bidirectional=bidir,\n",
    "    dropout=dropout,\n",
    "    num_class=len(PUNC_2_ID)\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_ID)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0\n",
    ")\n",
    "# scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    factor=0.5,  # default: 0.1\n",
    "    patience=2,  # default: 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "cfe0a51e-b34d-464e-8927-4dd64e96475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: \ttrain - 0.522074; \tval - 0.371870\t\ttime - 3.032 s\n",
      "Epoch #2: \ttrain - 0.353646; \tval - 0.326968\t\ttime - 5.998 s\n",
      "Epoch #3: \ttrain - 0.308811; \tval - 0.296496\t\ttime - 8.954 s\n",
      "Epoch #4: \ttrain - 0.275858; \tval - 0.278774\t\ttime - 11.877 s\n",
      "Epoch #5: \ttrain - 0.248955; \tval - 0.268314\t\ttime - 14.804 s\n",
      "Epoch #6: \ttrain - 0.225805; \tval - 0.261436\t\ttime - 17.758 s\n",
      "Epoch #7: \ttrain - 0.205653; \tval - 0.259821\t\ttime - 20.778 s\n",
      "Epoch #8: \ttrain - 0.187178; \tval - 0.260794\t\ttime - 23.706 s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "print_each = 1\n",
    "\n",
    "start_time = time.time()\n",
    "prev_val_loss = 100\n",
    "for epoch in range(n_epochs):\n",
    "    start_epoch_time = time.time()\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0):\n",
    "        print(f'Epoch #{epoch + 1}: ', end='')\n",
    "\n",
    "    # torch.manual_seed(48)  # for reproducibility\n",
    "    mean_train_loss = train_fn(model, train_loader, loss_func,\n",
    "                               optimizer,\n",
    "                               device=device,\n",
    "                               show_process=False\n",
    "                              )  # train the model\n",
    "    mean_val_loss = validate_fn(model, val_loader, loss_func,\n",
    "                                device=device,\n",
    "                                show_process=False\n",
    "                               )  # evaluate the model\n",
    "    \n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0):\n",
    "        log_info = (f'\\ttrain - {mean_train_loss:.6f}; ' +\n",
    "                    f'\\tval - {mean_val_loss:.6f}' + \n",
    "                    f'\\t\\ttime - {(time.time() - start_time):.3f} s'\n",
    "                   )\n",
    "        print(log_info)\n",
    "\n",
    "    if prev_val_loss < mean_val_loss:\n",
    "            break\n",
    "    prev_val_loss = mean_val_loss\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(mean_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cd6da267-5f74-4a90-8f38-7509e9c89765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "lstm_model_path = f'serialized/lstm-model_hidden-{hidden_sz}_layers-{num_layers}_bidir-{bidir}_dropout-{dropout:.2f}_celoss-{mean_val_loss:.3f}.pth'\n",
    "torch.save(model.state_dict(), lstm_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cec6b-a2c2-4daa-916e-7c6cfb73e74b",
   "metadata": {},
   "source": [
    "#### LSTM model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8e1cf862-2107-4438-8606-42ef57d88c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = LstmPunctuator(\n",
    "    hidden_size=hidden_sz, num_layers=num_layers, bidirectional=bidir,\n",
    "    dropout=dropout,\n",
    "    num_class=len(PUNC_2_ID)\n",
    ").to(device)\n",
    "\n",
    "# LOAD MODEL\n",
    "model_test.load_state_dict(torch.load(lstm_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c7a55af0-4160-467b-8aee-49eaa0bdc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_PUNC = ['F']\n",
    "INTR_PUNC = ['S', 'C']\n",
    "\n",
    "NAMES_PUNC = {\n",
    "    'S': 'space (` `)',\n",
    "    'C': 'comma (`,`)',\n",
    "    'F': 'end of sent',\n",
    "}\n",
    "\n",
    "CLASSES = sorted(END_PUNC + INTR_PUNC)  # alphabetic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "dcdf414b-83c5-4766-b20a-b3012803f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_df(model, test_df):\n",
    "    test_ds = PuncDataset(\n",
    "        df=test_df, \n",
    "        sent_col='input', \n",
    "        target_col='new_target',\n",
    "        embed=navec_embed\n",
    "    )  # test dataset\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=1, \n",
    "        drop_last=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0\n",
    "    )  # test DataLoader\n",
    "\n",
    "    all_test_targets = []  # by markers\n",
    "    all_test_preds = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, (data) in enumerate(test_loader):\n",
    "        padded_input, padded_target, input_lengths = data\n",
    "        all_test_targets.append(' '.join([ID_2_PUNC[ix.item()] for ix in padded_target[0]]))\n",
    "        \n",
    "        pred = model(padded_input, input_lengths)\n",
    "        pred = torch.argmax(pred.view(-1, pred.size(-1)), dim=1)\n",
    "        all_test_preds.append(' '.join([ID_2_PUNC[ix.item()] for ix in pred]))\n",
    "\n",
    "        assert len(pred) == len(padded_target[0])\n",
    "\n",
    "    # DataFrame with results\n",
    "    target_vs_pred_df = pd.DataFrame()\n",
    "\n",
    "    target_vs_pred_df['target'] = all_test_targets\n",
    "    target_vs_pred_df['predicted'] = all_test_preds\n",
    "\n",
    "    return target_vs_pred_df\n",
    "\n",
    "\n",
    "def return_separate_punct(target_vs_pred_df):\n",
    "    test_all_punc_target = []  # list of all punctuation\n",
    "    test_all_punc_preds = []\n",
    "    \n",
    "    for target_this, predicted_this in zip(target_vs_pred_df['target'], target_vs_pred_df['predicted']):\n",
    "        test_all_punc_target.extend(target_this.split(' '))\n",
    "        test_all_punc_preds.extend(predicted_this.split(' '))\n",
    "    \n",
    "    assert len(test_all_punc_target) == len(test_all_punc_preds)\n",
    "    \n",
    "    return test_all_punc_target, test_all_punc_preds\n",
    "\n",
    "\n",
    "def get_all_metrics(model, test_df):\n",
    "    target_vs_pred_df = get_predictions_df(model, test_df)\n",
    "    test_all_punc_target, test_all_punc_preds = return_separate_punct(target_vs_pred_df)\n",
    "\n",
    "    cm = confusion_matrix(test_all_punc_target, test_all_punc_preds)\n",
    "    # precision = TP / (TP + FP)\n",
    "    precision = precision_score(test_all_punc_target, test_all_punc_preds, average=None, zero_division=np.nan)\n",
    "    # recall = TP / (TP + FN)\n",
    "    recall = recall_score(test_all_punc_target, test_all_punc_preds, average=None, zero_division=np.nan)\n",
    "    # f1 = 2TP / (2TP + FP + FN)\n",
    "    f1 = f1_score(test_all_punc_target, test_all_punc_preds, average=None)\n",
    "\n",
    "    # PRINT\n",
    "    metrics_names = ['Precision', 'Recall', 'F1 score']\n",
    "    metrics = {'Precision': precision, 'Recall': recall, 'F1 score': f1}\n",
    "    col_w = 18\n",
    "    \n",
    "    print(' ' * col_w + '|' + ''.join([f\"{NAMES_PUNC[token] + (col_w - len(NAMES_PUNC[token])) * ' '}|\" for token in CLASSES]))  # header\n",
    "    print(''.join(['-' * col_w + '|' for _ in range(len(CLASSES) + 1)]) )\n",
    "    for ind, metric_name in enumerate(metrics_names):\n",
    "        row = f\"{metric_name + (col_w - len(metric_name)) * ' '}|\"\n",
    "        for score in metrics[metric_name]:\n",
    "            score_str = f'{score:.6f}'\n",
    "            row += f\"{score_str + (col_w - len(score_str)) * ' '}|\"\n",
    "        print(row)\n",
    "\n",
    "    # Levenshtein distance\n",
    "    print('\\nLevenshtein distance:')\n",
    "    target_vs_pred_df['levenshtein'] = target_vs_pred_df.apply(\n",
    "        lambda row: levenshtein_distance(row.target, row.predicted),\n",
    "        axis = 1\n",
    "    )\n",
    "    print(f\"\\tMean: {target_vs_pred_df['levenshtein'].mean()}\")\n",
    "    print(f\"\\tMIN : {target_vs_pred_df['levenshtein'].min()}\")\n",
    "    print(f\"\\tMAX : {target_vs_pred_df['levenshtein'].max()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "44438b94-c305-475d-9bf3-578b823f9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  |comma (`,`)       |end of sent       |space (` `)       |\n",
      "------------------|------------------|------------------|------------------|\n",
      "Precision         |0.687129          |1.000000          |0.918454          |\n",
      "Recall            |0.601647          |0.999102          |0.942514          |\n",
      "F1 score          |0.641553          |0.999551          |0.930329          |\n",
      "\n",
      "Levenshtein distance:\n",
      "\tMean: 1.3913824057450628\n",
      "\tMIN : 0\n",
      "\tMAX : 13\n",
      "\n",
      "CPU times: user 1.33 s, sys: 3.96 ms, total: 1.33 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_all_metrics(model_test, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3eddf5-ead7-42ef-8ae3-473530b86a22",
   "metadata": {},
   "source": [
    "**All metrics increased (except of small decreasing for `end of sentence` prediction) in contrast to metrics of X-Punctuator baseline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5ac7c74f-5560-4236-a9ae-f95ae89ae263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd5f7e-966b-4122-bcca-3927cd6e1eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9220a62-b519-4119-bed0-b84d4e9e9dc0",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "1da0ed9c-fb75-4d6e-8773-ac639ecb853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 15\n",
    "val_bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "66af8c47-b8cc-4fb8-8d84-b1d084b38008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=train_bs, \n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=val_bs, \n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "f771380d-2b99-4606-8eb3-d2d74c7ea8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "hidden_sz = 32\n",
    "num_layers = 2\n",
    "bidir = 1\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "8cdbefec-06b3-4ca2-be58-926062f917b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = GruPunctuator(\n",
    "    hidden_size=hidden_sz, num_layers=num_layers, bidirectional=bidir,\n",
    "    dropout=dropout,\n",
    "    num_class=len(PUNC_2_ID)\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_ID)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0\n",
    ")\n",
    "# scheduler\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "53c5dded-e610-49fd-ad4d-ff5f84349d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: \ttrain - 0.490619; \tval - 0.353615\t\ttime - 2.854 s\n",
      "Epoch #2: \ttrain - 0.329946; \tval - 0.302494\t\ttime - 5.676 s\n",
      "Epoch #3: \ttrain - 0.288781; \tval - 0.282932\t\ttime - 8.491 s\n",
      "Epoch #4: \ttrain - 0.266346; \tval - 0.270868\t\ttime - 11.322 s\n",
      "Epoch #5: \ttrain - 0.242723; \tval - 0.264213\t\ttime - 14.153 s\n",
      "Epoch #6: \ttrain - 0.224372; \tval - 0.261755\t\ttime - 16.976 s\n",
      "Epoch #7: \ttrain - 0.208505; \tval - 0.259991\t\ttime - 19.792 s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "print_each = 1\n",
    "\n",
    "val_loss_th = 0.26\n",
    "\n",
    "start_time = time.time()\n",
    "prev_val_loss = 100\n",
    "for epoch in range(n_epochs):\n",
    "    start_epoch_time = time.time()\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0):\n",
    "        print(f'Epoch #{epoch + 1}: ', end='')\n",
    "\n",
    "    # torch.manual_seed(48)  # for reproducibility\n",
    "    mean_train_loss = train_fn(model, train_loader, loss_func,\n",
    "                               optimizer,\n",
    "                               device=device,\n",
    "                               show_process=False\n",
    "                              )  # train the model\n",
    "    mean_val_loss = validate_fn(model, val_loader, loss_func,\n",
    "                                device=device,\n",
    "                                show_process=False\n",
    "                               )  # evaluate the model\n",
    "    \n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0):\n",
    "        log_info = (f'\\ttrain - {mean_train_loss:.6f}; ' +\n",
    "                    f'\\tval - {mean_val_loss:.6f}' + \n",
    "                    f'\\t\\ttime - {(time.time() - start_time):.3f} s'\n",
    "                   )\n",
    "        print(log_info)\n",
    "\n",
    "    if prev_val_loss < mean_val_loss or mean_val_loss < val_loss_th:\n",
    "            break\n",
    "    prev_val_loss = mean_val_loss\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(mean_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c3871-16c7-444f-b681-8df5e1e279b4",
   "metadata": {},
   "source": [
    "**There is noo significant difference with LSTM results...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "3864d651-4ddc-492b-b343-38e08f2d9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "gru_model_path = f'serialized/gru-model_hidden-{hidden_sz}_layers-{num_layers}_bidir-{bidir}_dropout-{dropout:.2f}_celoss-{mean_val_loss:.3f}.pth'\n",
    "torch.save(model.state_dict(), gru_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97297f-b6fa-473c-b8ff-e0644bd9cfcb",
   "metadata": {},
   "source": [
    "#### GRU model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "a723fc05-74c3-44b0-b0e1-4bb714c2b4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = GruPunctuator(\n",
    "    hidden_size=hidden_sz, num_layers=num_layers, bidirectional=bidir,\n",
    "    dropout=dropout,\n",
    "    num_class=len(PUNC_2_ID)\n",
    ").to(device)\n",
    "\n",
    "# LOAD MODEL\n",
    "model_test.load_state_dict(torch.load(gru_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "5784d95b-9a4c-4826-9ee8-902da79ceeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  |comma (`,`)       |end of sent       |space (` `)       |\n",
      "------------------|------------------|------------------|------------------|\n",
      "Precision         |0.723112          |1.000000          |0.909720          |\n",
      "Recall            |0.547898          |1.000000          |0.955976          |\n",
      "F1 score          |0.623428          |1.000000          |0.932275          |\n",
      "\n",
      "Levenshtein distance:\n",
      "\tMean: 1.3680430879712746\n",
      "\tMIN : 0\n",
      "\tMAX : 10\n",
      "\n",
      "CPU times: user 1.45 s, sys: 39.8 ms, total: 1.49 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "get_all_metrics(model_test, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb1686-6450-4ea4-ad53-e1b6a8dc32c6",
   "metadata": {},
   "source": [
    "Better identification of `end of sentence` token! No bugs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd363786-3127-49f7-8460-cfea120488c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
